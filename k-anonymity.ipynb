{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/owentsai/mambaforge/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.2.140)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torch in /home/owentsai/mambaforge/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in /home/owentsai/mambaforge/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: filelock in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.2.140)\n",
      "Requirement already satisfied: numpy in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torchvision) (1.25.2)\n",
      "Requirement already satisfied: requests in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/owentsai/mambaforge/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data = pd.read_csv(\"adult_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check if the subset satisfies k-anonymity\n",
    "def is_k_anonymous(subset, k):\n",
    "    return len(subset) >= k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_range(data, feature):\n",
    "    \"\"\"Calculate the value range of a feature.\"\"\"\n",
    "    if data[feature].dtype in [np.int64, np.float64]:  # 使用NumPy的數據類型來進行檢查\n",
    "        return data[feature].max() - data[feature].min()\n",
    "    else:  # For non-numeric features\n",
    "        return -np.inf  # Return a very small value to ensure this feature is not selected\n",
    "\n",
    "def split_on_feature(data, k):\n",
    "    \"\"\"Split the data based on the feature with the largest value range.\"\"\"\n",
    "    features = data.columns\n",
    "    max_range = -float(\"inf\")\n",
    "    split_feature = None\n",
    "\n",
    "    # Calculate the value range for each feature and find the feature with the largest range\n",
    "    for feature in features:\n",
    "        feature_range = calculate_range(data, feature)\n",
    "        if feature_range > max_range:\n",
    "            max_range = feature_range\n",
    "            split_feature = feature\n",
    "\n",
    "    # If we didn't find a feature to split on\n",
    "    if split_feature is None:\n",
    "        return data, pd.DataFrame()\n",
    "\n",
    "    # Split the data based on the median value of the selected feature\n",
    "    if data[split_feature].dtype in [int, float]:\n",
    "        median_value = data[split_feature].median()\n",
    "        subset1 = data[data[split_feature] < median_value]\n",
    "        subset2 = data[data[split_feature] >= median_value]\n",
    "    else:  # For categorical features, split based on whether the value is in the top 50% most common values\n",
    "        top_values = data[split_feature].value_counts().index[:len(data[split_feature].unique()) // 2]\n",
    "        subset1 = data[data[split_feature].isin(top_values)]\n",
    "        subset2 = data[~data[split_feature].isin(top_values)]\n",
    "\n",
    "    return subset1, subset2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_feature(data, feature):\n",
    "    \"\"\"Anonymize a numerical feature by replacing its values with a range.\"\"\"\n",
    "    if data[feature].dtype in [int, float]:  # Only apply for numerical features\n",
    "        min_val = data[feature].min()\n",
    "        max_val = data[feature].max()\n",
    "        range_str = f\"{min_val}-{max_val}\"\n",
    "        data[feature] = range_str\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mondrian_k_anonymization(data, k):\n",
    "    queue = [data]\n",
    "    results = []\n",
    "\n",
    "    while queue:\n",
    "        partition = queue.pop(0)\n",
    "\n",
    "        subset1, subset2 = split_on_feature(partition, k)\n",
    "\n",
    "        # 如果分割結果其中一個子集的大小小於k，則將原始分區添加到結果中\n",
    "        if len(subset1) < k or len(subset2) < k:\n",
    "            for feature in partition.columns:\n",
    "                partition = anonymize_feature(partition, feature)\n",
    "            results.append(partition)\n",
    "            continue\n",
    "        else:  # 如果兩個子集都滿足k-匿名性，則繼續分割它們\n",
    "            queue.append(subset1)\n",
    "            queue.append(subset2)\n",
    "\n",
    "    anonymized_data = pd.concat(results, axis=0, ignore_index=True)\n",
    "    return anonymized_data\n",
    "\n",
    "anonymized_data = mondrian_k_anonymization(adult_data, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_range_to_mean(data, feature):\n",
    "    \"\"\"Revert a range feature to its mean value.\"\"\"\n",
    "    # Check if the feature contains \"-\" and if the first split result can be converted to a float\n",
    "    if \"-\" in str(data[feature].iloc[0]):\n",
    "        try:\n",
    "            # Attempt to split and convert\n",
    "            min_vals, max_vals = data[feature].str.split(\"-\", expand=True).astype(float).values.T\n",
    "            data[feature] = 0.5 * (min_vals + max_vals)  # Take the average of the min and max\n",
    "        except ValueError:  # If conversion to float fails, it's not a numerical range and we skip it\n",
    "            pass\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in anonymized_data.columns:\n",
    "    anonymized_data = revert_range_to_mean(anonymized_data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Load the training data\n",
    "train_data = pd.read_csv('adult_data.csv')\n",
    "\n",
    "# Step 1.2: Encode categorical features and the target variable\n",
    "label_encoders = {}\n",
    "\n",
    "for column in train_data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    train_data[column] = le.fit_transform(train_data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Apply the same encoders to the anonymized_data\n",
    "for column in anonymized_data.select_dtypes(include=['object']).columns:\n",
    "    if column in label_encoders:\n",
    "        le = label_encoders[column]\n",
    "        anonymized_data[column] = le.transform(anonymized_data[column])\n",
    "\n",
    "# Step 1.3: Split the dataset into features and target\n",
    "X_train = train_data.drop('income', axis=1)\n",
    "y_train = train_data['income']\n",
    "\n",
    "# Step 1.4: Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(anonymized_data.drop('income', axis=1))\n",
    "y_test = anonymized_data['income']\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.int64)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2.1: Define the neural network\n",
    "class IncomeClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(IncomeClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)  # Two classes: <=50K and >50K\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = IncomeClassifier(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2880\n",
      "Epoch [2/10], Loss: 0.2706\n",
      "Epoch [3/10], Loss: 0.2588\n",
      "Epoch [4/10], Loss: 0.2496\n",
      "Epoch [5/10], Loss: 0.2459\n",
      "Epoch [6/10], Loss: 0.2443\n",
      "Epoch [7/10], Loss: 0.2426\n",
      "Epoch [8/10], Loss: 0.2401\n",
      "Epoch [9/10], Loss: 0.2368\n",
      "Epoch [10/10], Loss: 0.2340\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 3.1: Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 3.2: Set training parameters\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Step 3.3: Train the model\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        # Get mini-batch of data\n",
    "        inputs = X_train_tensor[i:i+batch_size]\n",
    "        labels = y_train_tensor[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.1: Test the model\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(test_outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification Error: 0.7617\n",
      "Accuracy: 0.2383\n",
      "Precision: 0.2367\n",
      "Recall: 0.9995\n",
      "AUC: 0.4898\n"
     ]
    }
   ],
   "source": [
    "# Convert tensors to numpy arrays for metric calculations\n",
    "predicted_np = predicted.numpy()\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "\n",
    "# Accuracy\n",
    "accuracy = (predicted_np == y_test_np).sum() / len(y_test_np)\n",
    "\n",
    "# Misclassification Error\n",
    "misclassification_error = 1 - accuracy\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test_np, predicted_np)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test_np, predicted_np)\n",
    "\n",
    "# AUC\n",
    "# First, get the predicted probabilities for the positive class\n",
    "probabilities = torch.nn.functional.softmax(test_outputs, dim=1)\n",
    "prob_pos_class = probabilities[:, 1].numpy()\n",
    "auc = roc_auc_score(y_test_np, prob_pos_class)\n",
    "\n",
    "print(f\"Misclassification Error: {misclassification_error:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Load the data\n",
    "train_data = pd.read_csv('adult_data.csv')\n",
    "test_data = pd.read_csv('adult_test.csv')\n",
    "\n",
    "# Step 1.2: Encode categorical features and the target variable\n",
    "label_encoders = {}\n",
    "\n",
    "for column in train_data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    train_data[column] = le.fit_transform(train_data[column])\n",
    "    test_data[column] = le.transform(test_data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Step 1.3: Split the dataset into features and target\n",
    "X_train = train_data.drop('income', axis=1)\n",
    "y_train = train_data['income']\n",
    "X_test = test_data.drop('income', axis=1)\n",
    "y_test = test_data['income']\n",
    "\n",
    "# Step 1.4: Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.int64)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2.1: Define the neural network\n",
    "class IncomeClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(IncomeClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)  # Two classes: <=50K and >50K\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = IncomeClassifier(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2890\n",
      "Epoch [2/10], Loss: 0.2693\n",
      "Epoch [3/10], Loss: 0.2562\n",
      "Epoch [4/10], Loss: 0.2501\n",
      "Epoch [5/10], Loss: 0.2432\n",
      "Epoch [6/10], Loss: 0.2355\n",
      "Epoch [7/10], Loss: 0.2328\n",
      "Epoch [8/10], Loss: 0.2288\n",
      "Epoch [9/10], Loss: 0.2257\n",
      "Epoch [10/10], Loss: 0.2240\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 3.1: Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 3.2: Set training parameters\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Step 3.3: Train the model\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        # Get mini-batch of data\n",
    "        inputs = X_train_tensor[i:i+batch_size]\n",
    "        labels = y_train_tensor[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.1: Test the model\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(test_outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification Error: 0.1507\n",
      "Accuracy: 0.8493\n",
      "Precision: 0.7130\n",
      "Recall: 0.6058\n",
      "AUC: 0.9043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Convert tensors to numpy arrays for metric calculations\n",
    "predicted_np = predicted.numpy()\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "\n",
    "# Accuracy\n",
    "accuracy = (predicted_np == y_test_np).sum() / len(y_test_np)\n",
    "\n",
    "# Misclassification Error\n",
    "misclassification_error = 1 - accuracy\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test_np, predicted_np)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test_np, predicted_np)\n",
    "\n",
    "# AUC\n",
    "# First, get the predicted probabilities for the positive class\n",
    "probabilities = torch.nn.functional.softmax(test_outputs, dim=1)\n",
    "prob_pos_class = probabilities[:, 1].numpy()\n",
    "auc = roc_auc_score(y_test_np, prob_pos_class)\n",
    "\n",
    "print(f\"Misclassification Error: {misclassification_error:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
